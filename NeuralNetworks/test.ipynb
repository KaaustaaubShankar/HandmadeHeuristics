{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Layers import ReLU, SoftMax, MSE\n",
    "def train_test_split(x_data, y_data, split_percentage=0.8, shuffle_train=True):\n",
    "    x_train, x_test, y_train, y_test = [], [], [], []\n",
    "    unique_digits = np.unique(y_data)\n",
    "\n",
    "    for digit in unique_digits:\n",
    "        digit_indices = np.where(y_data == digit)[0]\n",
    "        split_point = int(len(digit_indices) * split_percentage)\n",
    "        train_indices = digit_indices[:split_point]\n",
    "        test_indices = digit_indices[split_point:]\n",
    "        x_train.append(x_data[train_indices])\n",
    "        y_train.append(y_data[train_indices])\n",
    "        x_test.append(x_data[test_indices])\n",
    "        y_test.append(y_data[test_indices])\n",
    "\n",
    "    x_train = np.concatenate(x_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "    x_test = np.concatenate(x_test, axis=0)\n",
    "    y_test = np.concatenate(y_test, axis=0)\n",
    "\n",
    "    if shuffle_train:\n",
    "        shuffle_indices = np.random.permutation(len(x_train))\n",
    "        x_train = x_train[shuffle_indices]\n",
    "        y_train = y_train[shuffle_indices]\n",
    "\n",
    "    return x_train.T, x_test.T, y_train.T, y_test.T\n",
    "\n",
    "x_data = np.loadtxt('HW3_datafiles/MNISTnumImages5000_balanced.txt')  \n",
    "y_data = np.loadtxt('HW3_datafiles/MNISTnumLabels5000_balanced.txt')\n",
    "x_train, x_test,y_train,y_test = train_test_split(x_data, y_data, split_percentage=0.8, shuffle_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "m = 5000\n",
    "\n",
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / np.sum(np.exp(Z), axis=0, keepdims=True)\n",
    "    return A\n",
    "    \n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)  # Optionally keep softmax for probabilities; remove if not needed for MSE\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, int(Y.max()) + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y.astype(int)] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = 2 * (A2 - one_hot_Y) / m  # MSE loss gradient for output layer\n",
    "    dW2 = dZ2.dot(A1.T)\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = dZ1.dot(X.T)\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2    \n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[4 4 4 ... 4 9 4] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.1055\n",
      "Iteration:  10\n",
      "[4 4 4 ... 0 9 4] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.13975\n",
      "Iteration:  20\n",
      "[8 4 4 ... 0 9 4] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.21025\n",
      "Iteration:  30\n",
      "[8 4 4 ... 0 9 4] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.2655\n",
      "Iteration:  40\n",
      "[8 1 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.38225\n",
      "Iteration:  50\n",
      "[8 1 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.464\n",
      "Iteration:  60\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.528\n",
      "Iteration:  70\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.578\n",
      "Iteration:  80\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.6175\n",
      "Iteration:  90\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.6635\n",
      "Iteration:  100\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.69475\n",
      "Iteration:  110\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.7185\n",
      "Iteration:  120\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.738\n",
      "Iteration:  130\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.751\n",
      "Iteration:  140\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.7605\n",
      "Iteration:  150\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.76975\n",
      "Iteration:  160\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.7785\n",
      "Iteration:  170\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.78725\n",
      "Iteration:  180\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.794\n",
      "Iteration:  190\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.80175\n",
      "Iteration:  200\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.80775\n",
      "Iteration:  210\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.81125\n",
      "Iteration:  220\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8155\n",
      "Iteration:  230\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.81925\n",
      "Iteration:  240\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.825\n",
      "Iteration:  250\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.82925\n",
      "Iteration:  260\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.835\n",
      "Iteration:  270\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.83825\n",
      "Iteration:  280\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8425\n",
      "Iteration:  290\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.84425\n",
      "Iteration:  300\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.84825\n",
      "Iteration:  310\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8505\n",
      "Iteration:  320\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.85325\n",
      "Iteration:  330\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.855\n",
      "Iteration:  340\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.85575\n",
      "Iteration:  350\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8585\n",
      "Iteration:  360\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8615\n",
      "Iteration:  370\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8635\n",
      "Iteration:  380\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.86475\n",
      "Iteration:  390\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.86675\n",
      "Iteration:  400\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.86775\n",
      "Iteration:  410\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.86875\n",
      "Iteration:  420\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.87025\n",
      "Iteration:  430\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.87175\n",
      "Iteration:  440\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.873\n",
      "Iteration:  450\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.87375\n",
      "Iteration:  460\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8755\n",
      "Iteration:  470\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.87675\n",
      "Iteration:  480\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.877\n",
      "Iteration:  490\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8785\n",
      "Iteration:  500\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.87925\n",
      "Iteration:  510\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8795\n",
      "Iteration:  520\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.88075\n",
      "Iteration:  530\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.882\n",
      "Iteration:  540\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8825\n",
      "Iteration:  550\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.88375\n",
      "Iteration:  560\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.88425\n",
      "Iteration:  570\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.88475\n",
      "Iteration:  580\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.88475\n",
      "Iteration:  590\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.88625\n",
      "Iteration:  600\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.888\n",
      "Iteration:  610\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8895\n",
      "Iteration:  620\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.89075\n",
      "Iteration:  630\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.892\n",
      "Iteration:  640\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8925\n",
      "Iteration:  650\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.894\n",
      "Iteration:  660\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8945\n",
      "Iteration:  670\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.8955\n",
      "Iteration:  680\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.897\n",
      "Iteration:  690\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.89775\n",
      "Iteration:  700\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.89825\n",
      "Iteration:  710\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.9005\n",
      "Iteration:  720\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.902\n",
      "Iteration:  730\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.90225\n",
      "Iteration:  740\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.9025\n",
      "Iteration:  750\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.9035\n",
      "Iteration:  760\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.90525\n",
      "Iteration:  770\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.90575\n",
      "Iteration:  780\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.906\n",
      "Iteration:  790\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.9065\n",
      "Iteration:  800\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.90675\n",
      "Iteration:  810\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.907\n",
      "Iteration:  820\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.908\n",
      "Iteration:  830\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.90825\n",
      "Iteration:  840\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.90875\n",
      "Iteration:  850\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.90925\n",
      "Iteration:  860\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.9095\n",
      "Iteration:  870\n",
      "[8 3 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.90975\n",
      "Iteration:  880\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.9105\n",
      "Iteration:  890\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.91125\n",
      "Iteration:  900\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.91125\n",
      "Iteration:  910\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.91225\n",
      "Iteration:  920\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.913\n",
      "Iteration:  930\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.9135\n",
      "Iteration:  940\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.91375\n",
      "Iteration:  950\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.91425\n",
      "Iteration:  960\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.91525\n",
      "Iteration:  970\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.91525\n",
      "Iteration:  980\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.9155\n",
      "Iteration:  990\n",
      "[8 8 1 ... 0 9 3] [8. 8. 1. ... 0. 9. 3.]\n",
      "0.916\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(x_train, y_train, 0.10, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = x_train[:, index, None]\n",
    "    prediction = make_predictions(x_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [4]\n",
      "Label:  4.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "while True:\n",
    "    index = random.randint(0, x_train.shape[1] - 1)\n",
    "    test_prediction(index, W1, b1, W2, b2)\n",
    "    input(\"Press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
